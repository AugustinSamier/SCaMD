IFT_MODELS = [
    "TheBloke/Mistral-7B-Instruct-v0.2-AWQ",
    "TheBloke/zephyr-7B-beta-AWQ",
    "TheBloke/Llama-2-70B-Chat-AWQ",
    "TheBloke/Llama-2-13B-Chat-AWQ",
    "meta-llama/Meta-Llama-3-8B-Instruct",
    "casperhansen/llama-3-70b-instruct-awq",
    "meta-llama/Llama-2-7b-chat-hf",
    "meta-llama/Llama-2-13b-chat-hf",
    "Qwen/Qwen2-72B-Instruct-AWQ",
    "google/gemma-2-2b-it",
    "google/gemma-2-9b-it",
    "google/gemma-2-27b-it",
    "meta-llama/Meta-Llama-3.1-8B-Instruct",
    "hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4",
    "CohereForAI/c4ai-command-r-08-2024",
    "CohereForAI/c4ai-command-r-plus-08-2024",
    "CohereForAI/c4ai-command-r7b-12-2024",
    "command-r-08-2024",
    "command-r-plus-08-2024",
    "command-r7b-12-2024",
    "gpt-3.5-turbo-0125",
    "gpt-4o-mini-2024-07-18",
    "meta-llama/Llama-3.2-1B-Instruct",
    "meta-llama/Llama-3.2-3B-Instruct"
]

BASE_MODELS = [
    "TheBloke/Mistral-7B-v0.1-AWQ",
    "TheBloke/mixtral-8x7b-v0.1-AWQ",
    "TheBloke/Llama-2-70B-AWQ",
    "TheBloke/Mixtral-8x7B-Instruct-v0.1-GPTQ",
    "bigscience/bloom-560m",
    "bigscience/bloom-1b7",
    "bigscience/bloom-3b",
    "bigscience/bloom-7b1",
    "google/gemma-2b",
    "google/gemma-7b",
    "google/gemma-2-2b",
    "google/gemma-2-9b",
    "google/gemma-2-27b",
    "meta-llama/Llama-2-7b-hf",
    "meta-llama/Llama-2-13b-hf",
    "mistralai/Mistral-7B-v0.1",
    "allenai/OLMo-7B",
    "facebook/opt-6.7b",
    "facebook/xglm-7.5B",
    "babbage-002",
    "davinci-002",
    "gpt-3.5-turbo-instruct",
    "01-ai/Yi-6B",
    "meta-llama/Meta-Llama-3-8B",
    "meta-llama/Llama-3.1-8B",
    "haoranxu/ALMA-13B-R",
    "haoranxu/ALMA-13B",
    "haoranxu/ALMA-7B-R",
    "haoranxu/ALMA-7B",
    "kyutai/helium-1-preview-2b"
]